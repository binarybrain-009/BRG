{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-experimental langchain-community langchain networkx langchain-google-genai langchain-core json-repair tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ruWbyS15Gek",
        "outputId": "90bffaa9-f427-4e3b-87bf-9542cd1e0791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.3.25)\n",
            "Collecting json-repair\n",
            "  Downloading json_repair-0.35.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.24.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.35.0-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.24.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: filetype, python-dotenv, mypy-extensions, marshmallow, json-repair, httpx-sse, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-google-genai, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed dataclasses-json-0.6.7 filetype-1.2.0 httpx-sse-0.4.0 json-repair-0.35.0 langchain-0.3.14 langchain-community-0.3.14 langchain-core-0.3.29 langchain-experimental-0.3.4 langchain-google-genai-2.0.8 marshmallow-3.24.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_rule_to_mitre(rule, mitre_techniques):\n",
        "    print(f\"Mapping rule ID {rule['suri_rule_id']}...\")\n",
        "\n",
        "    # Create a set of valid technique IDs for validation\n",
        "    valid_technique_ids = {t['technique_id'] for t in mitre_techniques}\n",
        "\n",
        "    # Initial prompt for mapping\n",
        "    def create_prompt():\n",
        "        return f\"\"\"\n",
        "        You are a cybersecurity expert tasked with mapping Suricata IDS rules to MITRE ATT&CK techniques.\n",
        "\n",
        "        ### Instructions:\n",
        "        - Carefully analyze the rule classification and message to determine the intent of the activity.\n",
        "        - Use the provided MITRE ATT&CK techniques list to map the rule.\n",
        "        - If the rule involves scanning or probing a network broadly, map it to \"Active Scanning (T1595)\" under \"Reconnaissance (TA0043)\".\n",
        "        - If the rule focuses on identifying specific services on individual hosts, map it to \"Network Service Discovery (T1046)\" under \"Discovery (TA0007)\".\n",
        "        - For rules mentioning exploitation of public-facing services, use \"Exploit Public-Facing Application (T1190)\".\n",
        "        - Respond strictly with one of the techniques from the provided list.\n",
        "\n",
        "        ### Suricata Rule:\n",
        "        - ID: {rule[\"suri_rule_id\"]}\n",
        "        - Classification: {rule[\"suri_rule_classtype\"]}\n",
        "        - Message: \"{rule[\"suri_rule_msg\"]}\"\n",
        "\n",
        "        ### MITRE ATT&CK Techniques:\n",
        "        {json.dumps([{t['technique_id']: t['technique_name']} for t in mitre_techniques], indent=2)}\n",
        "\n",
        "        Respond in this exact JSON format:\n",
        "        {{\n",
        "            \"mitre_technique_id\": \"<Technique ID>\",\n",
        "            \"mitre_technique_name\": \"<Technique Name>\",\n",
        "            \"mitre_tactic_id\": \"<Tactic ID>\",\n",
        "            \"mitre_tactic_name\": \"<Tactic Name>\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "    # Helper function to interact with the LLM\n",
        "    def query_llm(prompt):\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a cybersecurity expert that maps Suricata rules to MITRE ATT&CK techniques.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=400,\n",
        "            temperature=0.0\n",
        "        )\n",
        "        return response\n",
        "\n",
        "    try:\n",
        "        # Track time for API call\n",
        "        start_time = time.time()\n",
        "        response = query_llm(create_prompt())\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        # Extract and clean response content\n",
        "        response_content = response.choices[0].message.content.strip()\n",
        "        print(f\"Raw response for rule ID {rule['suri_rule_id']}:\\n{response_content}\")\n",
        "\n",
        "        # Remove markdown formatting\n",
        "        cleaned_response = response_content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "        # Safely parse JSON\n",
        "        parsed_response = json.loads(cleaned_response)\n",
        "\n",
        "        # Validate technique ID\n",
        "        if parsed_response['mitre_technique_id'] not in valid_technique_ids:\n",
        "            print(f\"Invalid technique ID '{parsed_response['mitre_technique_id']}' for rule ID {rule['suri_rule_id']}. Retrying with stricter constraints...\")\n",
        "\n",
        "            # Retry prompt to enforce stricter constraints\n",
        "            retry_prompt = f\"\"\"\n",
        "            You previously mapped the rule to an invalid MITRE ATT&CK technique. Please remap it strictly using only the following list of valid techniques:\n",
        "\n",
        "            ### Valid MITRE ATT&CK Techniques:\n",
        "            {json.dumps([{t['technique_id']: t['technique_name']} for t in mitre_techniques], indent=2)}\n",
        "\n",
        "            ### Suricata Rule:\n",
        "            - ID: {rule[\"suri_rule_id\"]}\n",
        "            - Classification: {rule[\"suri_rule_classtype\"]}\n",
        "            - Message: \"{rule[\"suri_rule_msg\"]}\"\n",
        "\n",
        "            Respond in the same JSON format as before:\n",
        "            {{\n",
        "                \"mitre_technique_id\": \"<Technique ID>\",\n",
        "                \"mitre_technique_name\": \"<Technique Name>\",\n",
        "                \"mitre_tactic_id\": \"<Tactic ID>\",\n",
        "                \"mitre_tactic_name\": \"<Tactic Name>\"\n",
        "            }}\n",
        "            \"\"\"\n",
        "            retry_response = query_llm(retry_prompt)\n",
        "            retry_response_content = retry_response.choices[0].message.content.strip()\n",
        "            cleaned_retry_response = retry_response_content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "            parsed_retry_response = json.loads(cleaned_retry_response)\n",
        "\n",
        "            # Validate retry response\n",
        "            if parsed_retry_response['mitre_technique_id'] not in valid_technique_ids:\n",
        "                print(f\"Retry failed: Invalid technique ID again for rule ID {rule['suri_rule_id']}. Skipping this rule.\")\n",
        "                return None\n",
        "\n",
        "            print(f\"Rule ID {rule['suri_rule_id']} successfully remapped after retry.\")\n",
        "            return parsed_retry_response\n",
        "\n",
        "        print(f\"Rule ID {rule['suri_rule_id']} mapped successfully in {elapsed_time:.2f} seconds.\")\n",
        "        return parsed_response\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error: Invalid JSON format for rule ID {rule['suri_rule_id']}.\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing rule {rule['suri_rule_id']}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "gOCY5Rc2ngab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Jkrso35A2V",
        "outputId": "9be85cae-b8af-434c-b483-c488da60f040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading extracted rules from test_suricata_rules.json...\n",
            "Loaded 32 rules.\n",
            "\n",
            "Loading MITRE ATT&CK techniques from MITRE_ATTACK_TECHNIQUES.json...\n",
            "Loaded 52 MITRE ATT&CK techniques.\n",
            "\n",
            "Sample MITRE ATT&CK techniques:\n",
            "{\n",
            "    \"technique_id\": \"T1548\",\n",
            "    \"technique_name\": \"Abuse Elevation Control Mechanism\"\n",
            "}\n",
            "{\n",
            "    \"technique_id\": \"T1134\",\n",
            "    \"technique_name\": \"Access Token Manipulation\"\n",
            "}\n",
            "{\n",
            "    \"technique_id\": \"T1087\",\n",
            "    \"technique_name\": \"Account Discovery\"\n",
            "}\n",
            "{\n",
            "    \"technique_id\": \"T1098\",\n",
            "    \"technique_name\": \"Account Manipulation\"\n",
            "}\n",
            "{\n",
            "    \"technique_id\": \"T1595\",\n",
            "    \"technique_name\": \"Active Scanning\"\n",
            "}\n",
            "Starting mapping process...\n",
            "\n",
            "Processing rule 1/10: GPL ATTACK_RESPONSE id check returned root\n",
            "Mapping rule ID 2100498...\n",
            "Raw response for rule ID 2100498:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1068\",\n",
            "    \"mitre_technique_name\": \"Exploitation for Privilege Escalation\",\n",
            "    \"mitre_tactic_id\": \"TA0002\",\n",
            "    \"mitre_tactic_name\": \"Execution\"\n",
            "}\n",
            "```\n",
            "Rule ID 2100498 mapped successfully in 1.57 seconds.\n",
            "Processing rule 2/10: ET SCAN Potential SSH Scan\n",
            "Mapping rule ID 2001219...\n",
            "Raw response for rule ID 2001219:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1595\",\n",
            "    \"mitre_technique_name\": \"Active Scanning\",\n",
            "    \"mitre_tactic_id\": \"TA0043\",\n",
            "    \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "}\n",
            "```\n",
            "Rule ID 2001219 mapped successfully in 2.00 seconds.\n",
            "Processing rule 3/10: ET SCAN Potential VNC Scan 5800-5820\n",
            "Mapping rule ID 2002910...\n",
            "Raw response for rule ID 2002910:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1595\",\n",
            "    \"mitre_technique_name\": \"Active Scanning\",\n",
            "    \"mitre_tactic_id\": \"TA0043\",\n",
            "    \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "}\n",
            "```\n",
            "Rule ID 2002910 mapped successfully in 7.50 seconds.\n",
            "Processing rule 4/10: ET SCAN Potential VNC Scan 5900-5920\n",
            "Mapping rule ID 2002911...\n",
            "Raw response for rule ID 2002911:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1595\",\n",
            "    \"mitre_technique_name\": \"Active Scanning\",\n",
            "    \"mitre_tactic_id\": \"TA0043\",\n",
            "    \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "}\n",
            "```\n",
            "Rule ID 2002911 mapped successfully in 7.75 seconds.\n",
            "Processing rule 5/10: ET SCAN Potential SSH Scan OUTBOUND\n",
            "Mapping rule ID 2003068...\n",
            "Raw response for rule ID 2003068:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1595\",\n",
            "    \"mitre_technique_name\": \"Active Scanning\",\n",
            "    \"mitre_tactic_id\": \"TA0043\",\n",
            "    \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "}\n",
            "```\n",
            "Rule ID 2003068 mapped successfully in 1.28 seconds.\n",
            "Processing rule 6/10: ET SCAN Suspicious inbound to mySQL port 3306\n",
            "Mapping rule ID 2010937...\n",
            "Raw response for rule ID 2010937:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1595\",\n",
            "    \"mitre_technique_name\": \"Active Scanning\",\n",
            "    \"mitre_tactic_id\": \"TA0043\",\n",
            "    \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "}\n",
            "```\n",
            "Rule ID 2010937 mapped successfully in 5.30 seconds.\n",
            "Processing rule 7/10: ET SCAN Suspicious inbound to Oracle SQL port 1521\n",
            "Mapping rule ID 2010936...\n",
            "Raw response for rule ID 2010936:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1046\",\n",
            "    \"mitre_technique_name\": \"Network Service Discovery\",\n",
            "    \"mitre_tactic_id\": \"TA0007\",\n",
            "    \"mitre_tactic_name\": \"Discovery\"\n",
            "}\n",
            "```\n",
            "Rule ID 2010936 mapped successfully in 1.20 seconds.\n",
            "Processing rule 8/10: ET SCAN Suspicious inbound to MSSQL port 1433\n",
            "Mapping rule ID 2010935...\n",
            "Raw response for rule ID 2010935:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1595\",\n",
            "    \"mitre_technique_name\": \"Active Scanning\",\n",
            "    \"mitre_tactic_id\": \"TA0043\",\n",
            "    \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "}\n",
            "```\n",
            "Rule ID 2010935 mapped successfully in 7.68 seconds.\n",
            "Processing rule 9/10: ET SCAN NMAP OS Detection Probe\n",
            "Mapping rule ID 2018489...\n",
            "Raw response for rule ID 2018489:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1595\",\n",
            "    \"mitre_technique_name\": \"Active Scanning\",\n",
            "    \"mitre_tactic_id\": \"TA0043\",\n",
            "    \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "}\n",
            "```\n",
            "Rule ID 2018489 mapped successfully in 1.28 seconds.\n",
            "Processing rule 10/10: ET WEB_SERVER /bin/sh In URI Possible Shell Command Execution Attempt\n",
            "Mapping rule ID 2011465...\n",
            "Raw response for rule ID 2011465:\n",
            "```json\n",
            "{\n",
            "    \"mitre_technique_id\": \"T1190\",\n",
            "    \"mitre_technique_name\": \"Exploit Public-Facing Application\",\n",
            "    \"mitre_tactic_id\": \"TA0001\",\n",
            "    \"mitre_tactic_name\": \"Initial Access\"\n",
            "}\n",
            "```\n",
            "Invalid technique ID 'T1190' for rule ID 2011465. Retrying with stricter constraints...\n",
            "Rule ID 2011465 successfully remapped after retry.\n",
            "\n",
            "Saving mapping results to file...\n",
            "Mapping complete! Results saved to mapped_rules_to_mitre.json\n",
            "Total successfully mapped rules: 10 out of 10.\n",
            "Mapped rules saved to mapped_rules_to_mitre.json.\n"
          ]
        }
      ],
      "source": [
        "# Install OpenAI SDK if not installed\n",
        "\n",
        "# Import required libraries\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set OpenAI API key directly\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI(\n",
        "    api_key=os.environ['OPENAI_API_KEY']\n",
        ")\n",
        "\n",
        "\n",
        "# Load extracted rules\n",
        "def load_extracted_rules(file_path):\n",
        "    print(f\"Loading extracted rules from {file_path}...\")\n",
        "    with open(file_path, \"r\") as f:\n",
        "        rules = json.load(f)\n",
        "    print(f\"Loaded {len(rules)} rules.\\n\")\n",
        "    return rules\n",
        "\n",
        "# Load MITRE ATT&CK techniques\n",
        "def load_mitre_techniques(file_path):\n",
        "    print(f\"Loading MITRE ATT&CK techniques from {file_path}...\")\n",
        "    with open(file_path, \"r\") as f:\n",
        "        techniques = json.load(f)\n",
        "    print(f\"Loaded {len(techniques)} MITRE ATT&CK techniques.\\n\")\n",
        "    print(\"Sample MITRE ATT&CK techniques:\")\n",
        "    for technique in techniques[:5]:  # Print first 5 techniques\n",
        "        print(json.dumps(technique, indent=4))\n",
        "    return techniques\n",
        "\n",
        "# # Map a single rule to MITRE ATT&CK technique using LLM\n",
        "# def map_rule_to_mitre(rule, mitre_techniques):\n",
        "#     print(f\"Mapping rule ID {rule['suri_rule_id']}...\")\n",
        "\n",
        "#     # Create a set of valid technique IDs for validation\n",
        "#     valid_technique_ids = {t['technique_id'] for t in mitre_techniques}\n",
        "\n",
        "#     prompt = f\"\"\"\n",
        "#     You are a cybersecurity expert tasked with mapping Suricata IDS rules to MITRE ATT&CK techniques.\n",
        "\n",
        "#     ### Instructions:\n",
        "#     - Carefully analyze the rule classification and message to determine the intent of the activity.\n",
        "#     - Use the provided MITRE ATT&CK techniques list to map the rule.\n",
        "#     - If the rule involves scanning or probing a network broadly, map it to \"Active Scanning (T1595)\" under \"Reconnaissance (TA0043)\".\n",
        "#     - If the rule focuses on identifying specific services on individual hosts, map it to \"Network Service Discovery (T1046)\" under \"Discovery (TA0007)\".\n",
        "#     - For rules mentioning exploitation of public-facing services, use \"Exploit Public-Facing Application (T1190)\".\n",
        "#     - Respond strictly with one of the techniques from the provided list.\n",
        "\n",
        "#     ### Suricata Rule:\n",
        "#     - ID: {rule[\"suri_rule_id\"]}\n",
        "#     - Classification: {rule[\"suri_rule_classtype\"]}\n",
        "#     - Message: \"{rule[\"suri_rule_msg\"]}\"\n",
        "\n",
        "#     ### MITRE ATT&CK Techniques:\n",
        "#     {json.dumps([{t['technique_id']: t['technique_name']} for t in mitre_techniques], indent=2)}\n",
        "\n",
        "#     Respond in this exact JSON format:\n",
        "#     {{\n",
        "#         \"mitre_technique_id\": \"<Technique ID>\",\n",
        "#         \"mitre_technique_name\": \"<Technique Name>\",\n",
        "#         \"mitre_tactic_id\": \"<Tactic ID>\",\n",
        "#         \"mitre_tactic_name\": \"<Tactic Name>\"\n",
        "#     }}\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         # Track time for API call\n",
        "#         start_time = time.time()\n",
        "#         response = client.chat.completions.create(\n",
        "#             model=\"gpt-4o\",\n",
        "#             messages=[\n",
        "#                 {\"role\": \"system\", \"content\": \"You are a cybersecurity expert that maps Suricata rules to MITRE ATT&CK techniques.\"},\n",
        "#                 {\"role\": \"user\", \"content\": prompt}\n",
        "#             ],\n",
        "#             max_tokens=400,\n",
        "#             temperature=0.0\n",
        "#         )\n",
        "#         elapsed_time = time.time() - start_time\n",
        "\n",
        "#         # Extract and clean response content\n",
        "#         response_content = response.choices[0].message.content.strip()\n",
        "#         print(f\"Raw response for rule ID {rule['suri_rule_id']}:\\n{response_content}\")\n",
        "\n",
        "#         # Remove markdown formatting\n",
        "#         cleaned_response = response_content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "#         # Safely parse JSON\n",
        "#         try:\n",
        "#             parsed_response = json.loads(cleaned_response)\n",
        "\n",
        "#             # Validate technique ID\n",
        "#             if parsed_response['mitre_technique_id'] not in valid_technique_ids:\n",
        "#                 print(f\"Invalid technique ID '{parsed_response['mitre_technique_id']}' for rule ID {rule['suri_rule_id']}. Skipping this rule.\")\n",
        "#                 return None\n",
        "\n",
        "#             print(f\"Rule ID {rule['suri_rule_id']} mapped successfully in {elapsed_time:.2f} seconds.\")\n",
        "#             return parsed_response\n",
        "\n",
        "#         except json.JSONDecodeError as e:\n",
        "#             print(f\"Error: Invalid JSON format for rule ID {rule['suri_rule_id']}. Response: {cleaned_response}\")\n",
        "#             return None\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing rule {rule['suri_rule_id']}: {e}\")\n",
        "#         return None\n",
        "\n",
        "# Process first 100 rules\n",
        "def process_rules_and_map_to_mitre(extracted_rules, mitre_techniques, output_file):\n",
        "    print(\"Starting mapping process...\\n\")\n",
        "    mapped_results = []\n",
        "    total_rules = min(10, len(extracted_rules))  # Process up to 10 rules\n",
        "    for i, rule in enumerate(extracted_rules[:total_rules]):\n",
        "        print(f\"Processing rule {i+1}/{total_rules}: {rule['suri_rule_msg']}\")\n",
        "        mapping = map_rule_to_mitre(rule, mitre_techniques)\n",
        "        if mapping:\n",
        "            mapped_results.append({\n",
        "                \"suri_rule_id\": rule[\"suri_rule_id\"],\n",
        "                \"suri_rule_classtype\": rule[\"suri_rule_classtype\"],\n",
        "                \"suri_rule_msg\": rule[\"suri_rule_msg\"],\n",
        "                **mapping\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Skipping rule ID {rule['suri_rule_id']} due to an error.\")\n",
        "\n",
        "    print(\"\\nSaving mapping results to file...\")\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(mapped_results, f, indent=4)\n",
        "    print(f\"Mapping complete! Results saved to {output_file}\")\n",
        "    print(f\"Total successfully mapped rules: {len(mapped_results)} out of {total_rules}.\")\n",
        "\n",
        "# File paths (assumes files are in the same directory)\n",
        "extracted_rules_file = \"test_suricata_rules.json\"\n",
        "mitre_techniques_file = \"MITRE_ATTACK_TECHNIQUES.json\"\n",
        "output_file = \"mapped_rules_to_mitre.json\"\n",
        "\n",
        "# Load files\n",
        "extracted_rules = load_extracted_rules(extracted_rules_file)\n",
        "mitre_techniques = load_mitre_techniques(mitre_techniques_file)\n",
        "\n",
        "# Run the mapping\n",
        "process_rules_and_map_to_mitre(extracted_rules, mitre_techniques, output_file)\n",
        "\n",
        "# Output results (download the file in Colab, if needed)\n",
        "print(f\"Mapped rules saved to {output_file}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to calculate accuracy by comparing LLM output JSON with ground truth JSONL\n",
        "# and print differences\n",
        "\n",
        "# Define the file paths\n",
        "ground_truth_file = \"suri_to_mitre_map_v2.jsonl\"\n",
        "llm_output_file = \"mapped_rules_to_mitre.json\"\n",
        "\n",
        "# Load the ground truth data\n",
        "ground_truth = {}\n",
        "with open(ground_truth_file, \"r\") as f:\n",
        "    for line in f:\n",
        "        entry = json.loads(line)\n",
        "        ground_truth[entry[\"suri_rule_id\"]] = entry\n",
        "\n",
        "# Load the LLM output data\n",
        "with open(llm_output_file, \"r\") as f:\n",
        "    llm_output = json.load(f)\n",
        "\n",
        "# Initialize counters for accuracy calculation\n",
        "correct_mappings = 0\n",
        "total_mappings = len(llm_output)\n",
        "differences = []\n",
        "\n",
        "# Compare each LLM output entry with the ground truth\n",
        "for rule in llm_output:\n",
        "    rule_id = rule[\"suri_rule_id\"]\n",
        "    if rule_id in ground_truth:\n",
        "        gt = ground_truth[rule_id]\n",
        "        # Check if the LLM output matches the ground truth for the rule\n",
        "        if (\n",
        "            rule[\"mitre_technique_id\"] == gt[\"mitre_technique_id\"]\n",
        "        ):\n",
        "            correct_mappings += 1\n",
        "        else:\n",
        "            differences.append({\n",
        "                \"suri_rule_id\": rule_id,\n",
        "                \"ground_truth\": {\n",
        "                    \"mitre_technique_id\": gt[\"mitre_technique_id\"],\n",
        "                    \"mitre_technique_name\": gt[\"mitre_technique_name\"],\n",
        "                    \"mitre_tactic_id\": gt[\"mitre_tactic_id\"],\n",
        "                    \"mitre_tactic_name\": gt[\"mitre_tactic_name\"]\n",
        "                },\n",
        "                \"llm_output\": {\n",
        "                    \"mitre_technique_id\": rule[\"mitre_technique_id\"],\n",
        "                    \"mitre_technique_name\": rule[\"mitre_technique_name\"],\n",
        "                    \"mitre_tactic_id\": rule[\"mitre_tactic_id\"],\n",
        "                    \"mitre_tactic_name\": rule[\"mitre_tactic_name\"]\n",
        "                }\n",
        "            })\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (correct_mappings / total_mappings) * 100 if total_mappings > 0 else 0\n",
        "\n",
        "# Print the results\n",
        "print(f\"Total Rules Processed: {total_mappings}\")\n",
        "print(f\"Correct Mappings: {correct_mappings}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Print differences if any\n",
        "if differences:\n",
        "    print(\"\\nDifferences Found:\")\n",
        "    for diff in differences:\n",
        "        print(json.dumps(diff, indent=4))\n",
        "else:\n",
        "    print(\"\\nNo differences found between LLM output and ground truth.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqyySSR466CI",
        "outputId": "34c11a84-d457-4ad6-b7e6-c9d872749346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Rules Processed: 10\n",
            "Correct Mappings: 6\n",
            "Accuracy: 60.00%\n",
            "\n",
            "Differences Found:\n",
            "{\n",
            "    \"suri_rule_id\": \"2010937\",\n",
            "    \"ground_truth\": {\n",
            "        \"mitre_technique_id\": \"T1046\",\n",
            "        \"mitre_technique_name\": \"Network Service Discovery\",\n",
            "        \"mitre_tactic_id\": \"TA0007\",\n",
            "        \"mitre_tactic_name\": \"Discovery\"\n",
            "    },\n",
            "    \"llm_output\": {\n",
            "        \"mitre_technique_id\": \"T1595\",\n",
            "        \"mitre_technique_name\": \"Active Scanning\",\n",
            "        \"mitre_tactic_id\": \"TA0043\",\n",
            "        \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"suri_rule_id\": \"2010935\",\n",
            "    \"ground_truth\": {\n",
            "        \"mitre_technique_id\": \"T1046\",\n",
            "        \"mitre_technique_name\": \"Network Service Discovery\",\n",
            "        \"mitre_tactic_id\": \"TA0007\",\n",
            "        \"mitre_tactic_name\": \"Discovery\"\n",
            "    },\n",
            "    \"llm_output\": {\n",
            "        \"mitre_technique_id\": \"T1595\",\n",
            "        \"mitre_technique_name\": \"Active Scanning\",\n",
            "        \"mitre_tactic_id\": \"TA0043\",\n",
            "        \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"suri_rule_id\": \"2018489\",\n",
            "    \"ground_truth\": {\n",
            "        \"mitre_technique_id\": \"T1046\",\n",
            "        \"mitre_technique_name\": \"Network Service Discovery\",\n",
            "        \"mitre_tactic_id\": \"TA0007\",\n",
            "        \"mitre_tactic_name\": \"Discovery\"\n",
            "    },\n",
            "    \"llm_output\": {\n",
            "        \"mitre_technique_id\": \"T1595\",\n",
            "        \"mitre_technique_name\": \"Active Scanning\",\n",
            "        \"mitre_tactic_id\": \"TA0043\",\n",
            "        \"mitre_tactic_name\": \"Reconnaissance\"\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"suri_rule_id\": \"2011465\",\n",
            "    \"ground_truth\": {\n",
            "        \"mitre_technique_id\": \"T1190\",\n",
            "        \"mitre_technique_name\": \"Exploit Public-Facing Application\",\n",
            "        \"mitre_tactic_id\": \"TA0001\",\n",
            "        \"mitre_tactic_name\": \"Initial Access\"\n",
            "    },\n",
            "    \"llm_output\": {\n",
            "        \"mitre_technique_id\": \"T1059\",\n",
            "        \"mitre_technique_name\": \"Command and Scripting Interpreter\",\n",
            "        \"mitre_tactic_id\": \"TA0002\",\n",
            "        \"mitre_tactic_name\": \"Execution\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6ko5mt9hP71"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}