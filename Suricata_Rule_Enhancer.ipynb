{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5NuUXpeXTH8i"
      },
      "outputs": [],
      "source": [
        "#code the browse all the files in the rules folder and extract the  rules from the file and put it into csv file suricata_extracted_rules file\n",
        "#. Below is a breakdown of the individual rule files and the number of rules in each(doNT TAKE the rules that start with #):\n",
        "#1.\tCoresec Rules - 10 rules 2.\tBotcc.portgrouped.rules - 0 rules 3.\tBotcc.rules - 0 rules 4.\tCompromised.rules - 10 rules 5.\tDrop.rules - 10 rules 6.\tDshield.rules - 1 rule 7.\tEmerging-activex.rules - 19 rules 8.\tEmerging-adware_pup.rules - 10 rules 9.\tEmerging-attack_responses.rules - 10 rules 10.\tEmerging-chat.rules - 10 rules 11.\tEmerging-coinminer.rules - 10 rules 12.\tEmerging-current_event.rules - 10 rules 13.\tEmerging-deleted.rules - 0 rules 14.\tEmerging-dns.rules - 10 rules 15.\tEmerging-dos.rules - 10 rules 16.\tEmerging-dyn-dns.rules - 11 rules 17.\tEmerging-exploit_kit.rules - 10 rules 18.\tEmerging-exploit.rules - 10 rules 19.\tEmerging-file_sharing.rules - 10 rules 20.\tEmerging-ftp.rules - 10 rules 21.\tEmerging-game.rules - 11 rules 22.\tEmerging-hunting.rules - 10 rules 23.\tEmerging-icmp.rules - 10 rules 24.\tEmerging-imap.rules - 10 rules 25.\tEmerging-inappropriate.rules - 0 rules 26.\tEmerging-info.rules - 9 rules 27.\tEmerging-ja3.rules - 11 rules 28.\tEmerging-malware.rules - 10 rules 29.\tEmerging-misc.rules - 10 rules 30.\tEmerging-mobile_malware.rules - 10 rules 31.\tEmerging-netbios.rules - 11 rules 32.\tEmerging-p2p.rules - 10 rules 33.\tEmerging-phishing.rules - 10 rules 34.\tEmerging-pop3.rules - 9 rules 35.\tEmerging-remote_access.rules - 11 rules 36.\tEmerging-retired.rules - 10 rules 37.\tEmerging-rpc.rules - 10 rules 38.\tEmerging-scada.rules - 10 rules 39.\tEmerging-scan.rules - 10 rules 40.\tEmerging-shellcode.rules - 11 rules 41.\tEmerging-smtp.rules - 10 rules 42.\tEmerging-snmp.rules - 10 rules 43.\tEmerging-sql.rules - 10 rules 44.\tEmerging-ta_abused_services.rules - 10 rules 45.\tEmerging-telnet.rules - 8 rules 46.\tEmerging-tftp.rules - 12 rules 47.\tEmerging-user_agents.rules - 10 rules 48.\tEmerging-voip.rules - 10 rules 49.\tEmerging-web_client.rules - 11 rules 50.\tEmerging-web_server.rules - 10 rules 51.\tEmerging-web_specific_apps.rules - 10 rules 52.\tEmerging-worm.rules - 9 rules 53.\tThreatview_CS_c2.rules - 10 rules 54.\tTor.rules - 10 rules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "# Regex to capture:\n",
        "#   1. action (alert, drop, pass, etc.)\n",
        "#   2. protocol (ip, tcp, udp, etc.)\n",
        "#   3. src_addr (could be anything from IP to bracketed list, e.g. [1.2.3.0/24, ...])\n",
        "#   4. src_port\n",
        "#   5. dst_addr\n",
        "#   6. dst_port\n",
        "#   7. everything in parentheses (the rule options)\n",
        "rule_pattern = re.compile(\n",
        "    r'^(?P<action>\\S+)\\s+'        # action\n",
        "    r'(?P<proto>\\S+)\\s+'          # protocol\n",
        "    r'(?P<src_addr>\\S+)\\s+'       # src_addr\n",
        "    r'(?P<src_port>\\S+)\\s+->\\s+'  # src_port and arrow\n",
        "    r'(?P<dst_addr>\\S+)\\s+'       # dst_addr\n",
        "    r'(?P<dst_port>\\S+)\\s*'       # dst_port\n",
        "    r'\\((?P<options>.*)\\)$'       # everything inside parentheses\n",
        ")\n",
        "\n",
        "def extract_suricata_rules_parsed(rules_folder='rules', output_csv='suricata_extracted_rules_parsed.csv'):\n",
        "    \"\"\"\n",
        "    Scans all .rules files in the given 'rules_folder', extracts Suricata rules that\n",
        "    do not start with '#', tries to parse them into separate columns, and writes them\n",
        "    into a CSV file named 'output_csv'.\n",
        "    \"\"\"\n",
        "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\n",
        "            \"file_name\",\n",
        "            \"action\",\n",
        "            \"protocol\",\n",
        "            \"src_addr\",\n",
        "            \"src_port\",\n",
        "            \"dst_addr\",\n",
        "            \"dst_port\",\n",
        "            \"options\",      # full text in parentheses\n",
        "        ])\n",
        "\n",
        "        for filename in os.listdir(rules_folder):\n",
        "            if filename.endswith(\".rules\"):\n",
        "                file_path = os.path.join(rules_folder, filename)\n",
        "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as rule_file:\n",
        "                    for line in rule_file:\n",
        "                        line = line.strip()\n",
        "                        if (not line) or line.startswith('#'):\n",
        "                            continue\n",
        "                        lower_line = line.lower()\n",
        "                        if (lower_line.startswith('$id:') or\n",
        "                            'version' in lower_line or\n",
        "                            'generated' in lower_line):\n",
        "                            continue\n",
        "\n",
        "                        # Attempt to parse with our regex\n",
        "                        match = rule_pattern.match(line)\n",
        "                        if match:\n",
        "                            writer.writerow([\n",
        "                                filename,\n",
        "                                match.group('action'),\n",
        "                                match.group('proto'),\n",
        "                                match.group('src_addr'),\n",
        "                                match.group('src_port'),\n",
        "                                match.group('dst_addr'),\n",
        "                                match.group('dst_port'),\n",
        "                                match.group('options'),\n",
        "                            ])\n",
        "                        else:\n",
        "                            # If we can't parse with our regex, just store it in an \"unparsed\" row\n",
        "                            # or you could skip it entirely. Here weâ€™ll store with blank parsed fields.\n",
        "                            writer.writerow([filename, \"\", \"\", \"\", \"\", \"\", \"\", line])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_suricata_rules_parsed()\n"
      ],
      "metadata": {
        "id": "QPUOX1YITwRn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "def random_sample_from_csv(\n",
        "    input_csv='suricata_extracted_rules_parsed.csv',\n",
        "    output_csv='suricata_extracted_rules_random_sampled.csv',\n",
        "    max_rules_per_file=10\n",
        "):\n",
        "    data_by_filename = defaultdict(list)\n",
        "\n",
        "    # Read the entire CSV\n",
        "    with open(input_csv, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            data_by_filename[row['file_name']].append(row)\n",
        "\n",
        "    fieldnames = reader.fieldnames\n",
        "\n",
        "    # Write output\n",
        "    with open(output_csv, 'w', newline='', encoding='utf-8') as f_out:\n",
        "        writer = csv.DictWriter(f_out, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for filename, rows in data_by_filename.items():\n",
        "            # If fewer than max_rules_per_file, random.sample fails.\n",
        "            # We'll sample min(len(rows), max_rules_per_file).\n",
        "            sample_count = min(len(rows), max_rules_per_file)\n",
        "            sampled_rows = random.sample(rows, sample_count)\n",
        "            for row in sampled_rows:\n",
        "                writer.writerow(row)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    random_sample_from_csv(\n",
        "        input_csv='suricata_extracted_rules_parsed.csv',\n",
        "        output_csv='suricata_extracted_rules_random_sampled.csv',\n",
        "        max_rules_per_file=10\n",
        "    )"
      ],
      "metadata": {
        "id": "bu60WDw-XtCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plaiQvoZefkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}