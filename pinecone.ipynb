{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr0Y5LPa0ck2",
        "outputId": "3f6ba789-06d9-4f70-dafc-600d0354b544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PINECONE_API_KEY: pcsk_4iJy6B_4jDRvxB4cU9yVd8LHkZNZmqEMwoKkDVdzPEzuPycBfJDpvgbek6TBGKiozbjDwq\n",
            "OPENAI_KEY: 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\n"
          ]
        }
      ],
      "source": [
        "URL=\"\" #p[inecone url]\n",
        "import os\n",
        "\n",
        "# Replace these strings with your actual API keys\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"\"\n",
        "os.environ[\"OPENAI_KEY\"] = \"\"\n",
        "\n",
        "# Optionally print to verify they are set (optional, remove in production)\n",
        "print(\"PINECONE_API_KEY:\", os.environ.get(\"PINECONE_API_KEY\", \"Not found\"))\n",
        "print(\"OPENAI_KEY:\", os.environ.get(\"OPENAI_KEY\", \"Not found\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUILab4T1TOy",
        "outputId": "c479dc58-ea73-4a69-d016-a3aeda4ad346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pinecone-client\n",
            "  Using cached pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement unittest (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for unittest\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pinecone-client langchain_community unittest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krr6LSxS2mqg",
        "outputId": "0c956c08-6ee0-452b-c349-3a3be52cf359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Using cached langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.15 (from langchain_community)\n",
            "  Downloading langchain-0.3.15-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.31 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.31-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain_community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain_community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain_community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.15-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.15-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.31-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.2/412.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.29\n",
            "    Uninstalling langchain-core-0.3.29:\n",
            "      Successfully uninstalled langchain-core-0.3.29\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.14\n",
            "    Uninstalling langchain-0.3.14:\n",
            "      Successfully uninstalled langchain-0.3.14\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.15 langchain-core-0.3.31 langchain_community-0.3.15 marshmallow-3.25.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5BFFSIr3DrD",
        "outputId": "5f5284f8-7c46-43ab-e69e-e0d5d00a112e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Collecting pinecone\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2024.12.14)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Downloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone\n",
            "Successfully installed pinecone-5.4.2 pinecone-plugin-inference-3.1.0 pinecone-plugin-interface-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSwMS1BM2j5m",
        "outputId": "a7f939be-c4f3-46e5-a9fe-c78d5c445fd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "test_store_and_retrieve_file (__main__.TestExperienceManagerAndVectorDB.test_store_and_retrieve_file) ... ok\n",
            "test_store_and_retrieve_text (__main__.TestExperienceManagerAndVectorDB.test_store_and_retrieve_text) ... "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stored File Retrieval Results: [Document(metadata={}, page_content='This is a test file content for vector database.'), Document(metadata={}, page_content='This is a test file content for vector database.'), Document(metadata={}, page_content='This is a test file content for vector database.'), Document(metadata={}, page_content='This is a test text for vector database.')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 15.523s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stored Text Retrieval Results: [Document(metadata={}, page_content='This is a test text for vector database.'), Document(metadata={}, page_content='This is a test text for vector database.'), Document(metadata={}, page_content='This is a test text for vector database.'), Document(metadata={}, page_content='This is a test file content for vector database.')]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import unittest\n",
        "import time\n",
        "\n",
        "class TestExperienceManagerAndVectorDB(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        self.project_name = \"testautoattackerproject\"  # Must be lower-case, no special chars\n",
        "        self.vectordb_name = \"test_autoattacker_vectordb\"\n",
        "        # self.experience_manager = ExperienceManager(project_name=self.project_name,\n",
        "        #                                             vectordb_name=self.vectordb_name)\n",
        "        self.vector_db = customVectorDB(project_name=self.project_name,\n",
        "                                        vectordb_name=self.vectordb_name)\n",
        "\n",
        "    def tearDown(self):\n",
        "        # Optionally delete the index after tests\n",
        "        # self.vector_db.delete_index()\n",
        "        pass\n",
        "\n",
        "    def test_store_and_retrieve_text(self):\n",
        "        test_text = \"This is a test text for vector database.\"\n",
        "        self.vector_db.store_text(test_text)\n",
        "        time.sleep(5)  # Wait for indexing\n",
        "        results = self.vector_db.retrieval(\"test text\")\n",
        "        print(\"Stored Text Retrieval Results:\", results)\n",
        "        self.assertGreater(len(results), 0)\n",
        "        if results:\n",
        "            self.assertIn(\"This is a test text for vector database.\", results[0].page_content)\n",
        "\n",
        "    def test_store_and_retrieve_file(self):\n",
        "        test_file_content = \"This is a test file content for vector database.\"\n",
        "        with open(\"test_file.txt\", \"w\") as f:\n",
        "            f.write(test_file_content)\n",
        "\n",
        "        self.vector_db.store_file(\"test_file.txt\")\n",
        "        time.sleep(5)\n",
        "        results = self.vector_db.retrieval(\"test file content\")\n",
        "        print(\"Stored File Retrieval Results:\", results)\n",
        "        self.assertGreater(len(results), 0)\n",
        "        if results:\n",
        "            self.assertIn(\"This is a test file content for vector database.\", results[0].page_content)\n",
        "\n",
        "    # def test_store_and_retrieve_experience(self):\n",
        "    #     test_action_plan = \"Execute shell command to escalate privileges.\"\n",
        "    #     self.experience_manager.store_experience(test_action_plan, metadata=None)\n",
        "    #     time.sleep(5)\n",
        "    #     results = self.experience_manager.retrieve_experiences(\"escalate privileges\", top_k=1)\n",
        "    #     print(\"Stored Experience Retrieval Results:\", results)\n",
        "    #     self.assertGreater(len(results), 0)\n",
        "    #     if results:\n",
        "    #         self.assertIn(\"Execute shell command to escalate privileges.\", results[0].page_content)\n",
        "\n",
        "\n",
        "# Run the tests\n",
        "suite = unittest.TestLoader().loadTestsFromTestCase(TestExperienceManagerAndVectorDB)\n",
        "unittest.TextTestRunner(verbosity=2).run(suite)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ407TNl53og"
      },
      "outputs": [],
      "source": [
        "def push_techniques_to_experience_manager(json_file_path: str, manager: ExperienceManager):\n",
        "    with open(json_file_path, \"r\") as f:\n",
        "        techniques = json.load(f)\n",
        "\n",
        "    for technique in techniques:\n",
        "        # Combine fields into a single text block\n",
        "        text_content = (\n",
        "            f\"Technique ID: {technique.get('technique_id', '')}\\n\"\n",
        "            f\"Technique Name: {technique.get('technique_name', '')}\\n\\n\"\n",
        "            f\"{technique.get('technique_description', '')}\"\n",
        "        )\n",
        "\n",
        "        # Optional: store some metadata as a list of dict or just a single dict\n",
        "        metadata = [{\n",
        "            \"technique_id\": technique.get(\"technique_id\", \"\"),\n",
        "            \"technique_name\": technique.get(\"technique_name\", \"\"),\n",
        "        }]\n",
        "\n",
        "        # Store via ExperienceManager\n",
        "        manager.store_experience(text_content, metadata=metadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhieyFDa53xS",
        "outputId": "d8a5b334-dfb8-4779-e4f9-40c9a145ab09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (5.0.1)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2024.12.14)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.31)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain_community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain_community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_community) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Results for query: 'Password Filter DLL'\n",
            "\n",
            "Result 1 Content:\n",
            " Technique ID: T1201\n",
            "Technique Name: Password Policy Discovery\n",
            "\n",
            "Adversaries may attempt to access detailed information about the password policy used within an enterprise network or cloud environment. Password policies are a way to enforce complex passwords that are difficult to guess or crack through Brute Force. This information may help the adversary to create a list of common passwords and launch dictionary and/or brute force attacks which adheres to the policy (e.g. if the minimum password length should be 8, then not trying passwords such as 'pass123'; not checking for more than 3-4 passwords per account if the lockout is set to 6 as to not lock out accounts).\n",
            "Metadata: {'technique_id': 'T1201', 'technique_name': 'Password Policy Discovery'}\n",
            "\n",
            "Result 2 Content:\n",
            " Technique ID: T1555\n",
            "Technique Name: Credentials from Password Stores\n",
            "\n",
            "Adversaries may search for common password storage locations to obtain user credentials. Passwords are stored in several places on a system, depending on the operating system or application holding the credentials. There are also specific applications and services that store passwords to make them easier for users to manage and maintain, such as password managers and cloud secrets vaults. Once credentials are obtained, they can be used to perform lateral movement and access restricted information.\n",
            "Metadata: {'technique_id': 'T1555', 'technique_name': 'Credentials from Password Stores'}\n",
            "\n",
            "Result 3 Content:\n",
            " Technique ID: T1556\n",
            "Technique Name: Modify Authentication Process\n",
            "\n",
            "Adversaries may modify authentication mechanisms and processes to access user credentials or enable otherwise unwarranted access to accounts. The authentication process is handled by mechanisms, such as the Local Security Authentication Server (LSASS) process and the Security Accounts Manager (SAM) on Windows, pluggable authentication modules (PAM) on Unix-based systems, and authorization plugins on MacOS systems, responsible for gathering, storing, and validating credentials. By modifying an authentication process, an adversary may be able to authenticate to a service or system without using Valid Accounts.\n",
            "Metadata: {'technique_id': 'T1556', 'technique_name': 'Modify Authentication Process'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import uuid\n",
        "import pinecone\n",
        "import time\n",
        "import json\n",
        "from typing import List\n",
        "\n",
        "# Install necessary packages (if not already installed)\n",
        "!pip install pinecone-client langchain_community\n",
        "\n",
        "# Set environment variables (replace with your actual keys)\n",
        "# os.environ[\"PINECONE_API_KEY\"] = \"YOUR_PINECONE_API_KEY\"\n",
        "# os.environ[\"OPENAI_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
        "\n",
        "# LangChain-related imports\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.vectorstores import Pinecone\n",
        "\n",
        "from pinecone import Pinecone as PineconeClient, ServerlessSpec\n",
        "\n",
        "\n",
        "class customVectorDB:\n",
        "    \"\"\"\n",
        "    The custom VectorDB implementation behind Pinecone to support the chatbot.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, project_name: str, vectordb_name: str):\n",
        "        assert project_name != \"\", \"Project name cannot be empty.\"\n",
        "        self.project_name = project_name\n",
        "\n",
        "        # Load environment variables\n",
        "        pinecone_api_key = os.getenv(\"PINECONE_API_KEY\", \"\")\n",
        "        os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_KEY\", \"\")\n",
        "\n",
        "        # In Colab, create a local directory if you wish.\n",
        "        self.vectordb_directory = vectordb_name\n",
        "        if not os.path.exists(self.vectordb_directory):\n",
        "            os.mkdir(self.vectordb_directory)\n",
        "\n",
        "        self.uuid = str(uuid.uuid4())\n",
        "        self.local_context_directory = os.path.join(\n",
        "            self.vectordb_directory, self.project_name + \"_\" + self.uuid\n",
        "        )\n",
        "        if not os.path.exists(self.local_context_directory):\n",
        "            os.mkdir(self.local_context_directory)\n",
        "\n",
        "        # Initialize Pinecone\n",
        "        self.pinecone_instance = PineconeClient(api_key=pinecone_api_key)\n",
        "        existing_indexes = self.pinecone_instance.list_indexes().names()\n",
        "\n",
        "        if self.project_name not in existing_indexes:\n",
        "            self.pinecone_instance.create_index(\n",
        "                name=self.project_name,\n",
        "                dimension=1536,  # 'text-embedding-ada-002' uses 1536 dimensions\n",
        "                metric=\"cosine\",\n",
        "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "            )\n",
        "\n",
        "        self.vectorDB = Pinecone.from_existing_index(\n",
        "            self.project_name,\n",
        "            OpenAIEmbeddings()\n",
        "        )\n",
        "\n",
        "    def __del__(self):\n",
        "        pass\n",
        "\n",
        "    def _save_text(self, _text: str) -> str:\n",
        "        filename = str(uuid.uuid4()) + \".txt\"\n",
        "        file_path = os.path.join(self.local_context_directory, filename)\n",
        "        with open(file_path, \"w\") as f:\n",
        "            f.write(_text)\n",
        "        return file_path\n",
        "\n",
        "    def store_file(self, filename: str, metadata: List[dict] = None):\n",
        "        loader = TextLoader(filename)\n",
        "        documents = loader.load()\n",
        "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "        texts = text_splitter.split_documents(documents)\n",
        "        string_texts = [t.page_content for t in texts]\n",
        "        self.vectorDB.add_texts(\n",
        "            texts=string_texts,\n",
        "            metadatas=metadata if metadata else None\n",
        "        )\n",
        "\n",
        "    def store_text(self, content: str, metadata: List[dict] = None):\n",
        "        filename = self._save_text(content)\n",
        "        self.store_file(filename, metadata=metadata)\n",
        "\n",
        "    def retrieval(self, keyword: str, metadata: List[dict] = None) -> List[dict]:\n",
        "        return self.vectorDB.similarity_search(keyword)\n",
        "\n",
        "    def delete_index(self):\n",
        "        self.pinecone_instance.delete_index(name=self.project_name)\n",
        "\n",
        "\n",
        "class ExperienceManager:\n",
        "    def __init__(self, project_name: str, vectordb_name: str):\n",
        "        self.vector_db = customVectorDB(project_name, vectordb_name)\n",
        "\n",
        "    def store_experience(self, action_plan: str, metadata: List[dict] = None):\n",
        "        self.vector_db.store_text(action_plan, metadata=metadata)\n",
        "\n",
        "    def retrieve_experiences(self, query: str, top_k: int = 3) -> List[dict]:\n",
        "        results = self.vector_db.retrieval(query)\n",
        "        return results[:top_k]\n",
        "\n",
        "\n",
        "# Instantiate your customVectorDB and ExperienceManager\n",
        "project_name = \"testautoattackerproject\"\n",
        "vectordb_name = \"test_autoattacker_vectorDB\"\n",
        "\n",
        "vector_db = customVectorDB(project_name, vectordb_name)  # if you want direct access\n",
        "manager = ExperienceManager(project_name, vectordb_name) # if you prefer the manager\n",
        "json_file_path = \"techniques.json\"  # The file you uploaded\n",
        "push_techniques_to_experience_manager(json_file_path, manager)\n",
        "\n",
        "# Wait a few seconds for indexing if you want to test retrieval immediately\n",
        "time.sleep(5)\n",
        "\n",
        "# Example retrieval\n",
        "query = \"Password Filter DLL\"\n",
        "results = manager.retrieve_experiences(query)\n",
        "print(f\"Results for query: '{query}'\")\n",
        "for idx, doc in enumerate(results):\n",
        "    print(f\"\\nResult {idx+1} Content:\\n\", doc.page_content)\n",
        "    print(\"Metadata:\", doc.metadata)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
